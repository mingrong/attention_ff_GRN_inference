{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e1d0c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import numpy as np  \n",
    "from earlystopping import EarlyStopping\n",
    "from torch.nn import functional as F\n",
    "import dgl.function as fn\n",
    "from models import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2787bd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cerevisiae,silico,coli\n",
    "name='cerevisiae'\n",
    "expression,network,tfs=load_data_new(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "430f8b8f-58f6-47cd-9272-5ac139d6d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_sub_index=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e17aaf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data=scaler.fit_transform(expression).T\n",
    "# def max_scale(X):\n",
    "#     return X/X.max(axis=1).reshape(-1,1)   \n",
    "# data=max_scale(expression.values.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a641425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adj_l,adj_m,adj_row=adj_list(data,min_k=1,metric='pearson',dr=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76e978fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a,b=data[np.array(adj_l)[:,0]],data[np.array(adj_l)[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50b641cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr1_data=np.concatenate((a,b),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "524e8fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expression=pd.DataFrame(data.T, columns=expression.columns)\n",
    "# df_expression=expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cca4cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_gene=network[0].values\n",
    "dst_gene=network[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e579ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_expression_df=df_expression[src_gene]\n",
    "dst_expression_df=df_expression[dst_gene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10e71ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x=torch.tensor(src_expression_df.T.values,dtype=torch.float32)\n",
    "input_y=torch.tensor(dst_expression_df.T.values,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afca8542",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a7bc31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c3ef745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs=torch.cat([input_x,input_y],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4349f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler2 = MinMaxScaler()\n",
    "# data1=scaler2.fit_transform(inputs.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbf2b62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs=torch.tensor(data,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d52bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs=torch.cat([input_x,input_y],1)\n",
    "# inputs=np.hstack((input_x,input_y)).reshape(input_x.shape[0],2,input_x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb7129a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs=torch.tensor(inputs,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ee39a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0cb4e7-f568-4a9e-a8cd-6f95f7ea9bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b785e784",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fusion1(nn.Module):\n",
    "    def __init__(self, infeats,hid_feat,out_feat, reduction=16):\n",
    "        super(fusion1, self).__init__()\n",
    "#         self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(infeats*2, infeats*2 // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(infeats*2 // reduction, infeats, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.fc1=nn.Linear(infeats*2, infeats*2 // reduction, bias=False)\n",
    "        self.fc2= nn.Linear(infeats*2 // reduction, infeats, bias=False)\n",
    "        self.fc3= nn.Linear(infeats*2 // reduction, infeats, bias=False)\n",
    "        self.x_layer=nn.Linear(in_feats,in_feats*2)\n",
    "        self.y_layer=nn.Linear(in_feats,in_feats*2)\n",
    "        self.mlp=nn.Sequential(\n",
    "            nn.Linear(in_feats*2, hid_feat),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hid_feat, hid_feat),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hid_feat, out_feat)            \n",
    "        )\n",
    "        self.sig=nn.Sigmoid()\n",
    "    def Norm(self,inp):\n",
    "        return (inp-inp.mean(axis=1).view(-1,1))/inp.std(axis=1).view(-1,1)  \n",
    "    \n",
    "    def forward(self, x,y,inputs):\n",
    "        \n",
    "#         xy=self.fc(inputs)\n",
    "#         xyl=torch.cat([x*xy,y*xy],1)\n",
    "#         xy=xy*inputs\n",
    "#         xy=self.sig(xy)\n",
    "        xy1=self.fc1(inputs)\n",
    "        xy1=F.relu(xy1)\n",
    "        xy2=self.fc2(xy1)\n",
    "        xy3=self.fc3(xy1)\n",
    "        xy2=self.sig(xy2)\n",
    "        xy3=self.sig(xy3)\n",
    "        xl=self.Norm(x*xy2)\n",
    "        yl=self.Norm(y*xy3)\n",
    "#         xyl=self.Norm(xyl)\n",
    "        xyl=torch.cat([xl,yl],1)\n",
    "#         xyl=inputs*xy\n",
    "#         xyl=self.Norm(xyl)\n",
    "        xyl=self.mlp(xyl)\n",
    "        \n",
    "        return torch.sigmoid(xyl)\n",
    "# #         b, c, _, _ = x.size()\n",
    "# #         y = self.avg_pool(x).view(b, c)\n",
    "# #         y = self.fc(y).view(b, c, 1, 1)\n",
    "# #         return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "232c31b1-4cab-43ba-8733-630168cddf2d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class fusion2(nn.Module):\n",
    "#     def __init__(self, infeats,hid_feat,out_feat, reduction=16):\n",
    "#         super(fusion2, self).__init__()\n",
    "# #         self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(infeats*2, infeats*2 // reduction, bias=False),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(infeats*2 // reduction, infeats*2, bias=False),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "#         self.xy_layer=nn.Linear(in_feats*2,in_feats)\n",
    "#         self.y_layer=nn.Linear(in_feats,in_feats*2)\n",
    "#         self.mlp=nn.Sequential(\n",
    "#             nn.Linear(in_feats*2, hid_feat),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(hid_feat, hid_feat),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(hid_feat, out_feat)            \n",
    "#         )\n",
    "#         self.sig=nn.Sigmoid()\n",
    "#     def Norm(self,inp):\n",
    "#         return (inp-inp.mean(axis=1).view(-1,1))/inp.std(axis=1).view(-1,1)  \n",
    "    \n",
    "#     def forward(self, x,y,inputs):\n",
    "        \n",
    "#         xy=self.fc(inputs)\n",
    "# #         xyl=torch.cat([x*xy,y*xy],1)\n",
    "# #         xy=xy*inputs\n",
    "# #         xy=self.sig(xy)\n",
    "# #         xy=\n",
    "#         xy=self.sig(self.xy_layer(self.Norm(inputs*xy)))\n",
    "        \n",
    "#         xl=self.Norm(x*xy)\n",
    "#         yl=self.Norm(y*xy)\n",
    "# #         xyl=self.Norm(xyl)\n",
    "#         xyl=torch.cat([xl,yl],1)\n",
    "# #         xyl=inputs*xy\n",
    "# #         xyl=self.Norm(xyl)\n",
    "#         xyl=self.mlp(xyl)\n",
    "        \n",
    "#         return torch.sigmoid(xyl)\n",
    "# # #         b, c, _, _ = x.size()\n",
    "# # #         y = self.avg_pool(x).view(b, c)\n",
    "# # #         y = self.fc(y).view(b, c, 1, 1)\n",
    "# # #         return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f104708-8686-4acb-a556-2cf074ff826a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class fusion3(nn.Module):\n",
    "#     def __init__(self, infeats,hid_feat,out_feat, reduction=16):\n",
    "#         super(fusion3, self).__init__()\n",
    "# #         self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(infeats, infeats // reduction, bias=False),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(infeats // reduction, infeats, bias=False),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "#         self.xy_layer=nn.Linear(in_feats*2,in_feats)\n",
    "#         self.y_layer=nn.Linear(in_feats,in_feats*2)\n",
    "#         self.mlp=nn.Sequential(\n",
    "#             nn.Linear(in_feats*2, hid_feat),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(hid_feat, hid_feat),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(hid_feat, out_feat)            \n",
    "#         )\n",
    "#         self.sig=nn.Sigmoid()\n",
    "#     def Norm(self,inp):\n",
    "#         return (inp-inp.mean(axis=1).view(-1,1))/inp.std(axis=1).view(-1,1)  \n",
    "    \n",
    "#     def forward(self, x,y,inputs):\n",
    "#         residual_x=x\n",
    "#         residual_y=y\n",
    "        \n",
    "#         out_x=self.fc(x)\n",
    "#         out_y=self.fc(y)\n",
    "        \n",
    "#         out_x=self.Norm(residual_x*out_x)\n",
    "#         out_y=self.Norm(residual_y*out_y)\n",
    "        \n",
    "#         xy=torch.cat([out_x,out_y],1)\n",
    "        \n",
    "# #         xy=self.fc(inputs)\n",
    "# # #         xyl=torch.cat([x*xy,y*xy],1)\n",
    "# # #         xy=xy*inputs\n",
    "# # #         xy=self.sig(xy)\n",
    "# # #         xy=\n",
    "# #         xy=self.sig(self.xy_layer(self.Norm(inputs*xy)))\n",
    "        \n",
    "# #         xl=self.Norm(x*xy)\n",
    "# #         yl=self.Norm(y*xy)\n",
    "# # #         xyl=self.Norm(xyl)\n",
    "# #         xyl=torch.cat([xl,yl],1)\n",
    "# # #         xyl=inputs*xy\n",
    "# # #         xyl=self.Norm(xyl)\n",
    "#         xyl=self.mlp(xy)\n",
    "        \n",
    "#         return torch.sigmoid(xyl)\n",
    "# # #         b, c, _, _ = x.size()\n",
    "# # #         y = self.avg_pool(x).view(b, c)\n",
    "# # #         y = self.fc(y).view(b, c, 1, 1)\n",
    "# # #         return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a176e538-e7d9-4fd8-ab22-a510d317e7ff",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class fusion4(nn.Module):\n",
    "#     def __init__(self, infeats,hid_feat,out_feat, reduction=16):\n",
    "#         super(fusion4, self).__init__()\n",
    "# #         self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(infeats, infeats // reduction, bias=False),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(infeats // reduction, infeats, bias=False),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "    \n",
    "#         self.fc2 = nn.Sequential(\n",
    "#             nn.Linear(infeats*2, infeats*2 // reduction*2, bias=False),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(infeats*2 // reduction*2, infeats*2, bias=False),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "#         self.xy_layer=nn.Linear(in_feats*2,in_feats)\n",
    "#         self.y_layer=nn.Linear(in_feats,in_feats*2)\n",
    "#         self.mlp=nn.Sequential(\n",
    "#             nn.Linear(in_feats*2, hid_feat),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(hid_feat, hid_feat),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Linear(hid_feat, out_feat)            \n",
    "#         )\n",
    "#         self.sig=nn.Sigmoid()\n",
    "#     def Norm(self,inp):\n",
    "#         return (inp-inp.mean(axis=1).view(-1,1))/inp.std(axis=1).view(-1,1)  \n",
    "    \n",
    "#     def forward(self, x,y,inputs):\n",
    "#         residual_x=x\n",
    "#         residual_y=y\n",
    "        \n",
    "#         out_x=self.fc(x)\n",
    "#         out_y=self.fc(y)\n",
    "        \n",
    "#         out_x=self.Norm(residual_x*out_x)\n",
    "#         out_y=self.Norm(residual_y*out_y)\n",
    "        \n",
    "#         xy=torch.cat([out_x,out_y],1)\n",
    "        \n",
    "#         xy_fc=self.fc2(xy)\n",
    "#         xy_m=xy_fc*inputs\n",
    "#         xy_m=self.Norm(xy_m)\n",
    "        \n",
    "# #         xy=self.fc(inputs)\n",
    "# # #         xyl=torch.cat([x*xy,y*xy],1)\n",
    "# # #         xy=xy*inputs\n",
    "# # #         xy=self.sig(xy)\n",
    "# # #         xy=\n",
    "# #         xy=self.sig(self.xy_layer(self.Norm(inputs*xy)))\n",
    "        \n",
    "# #         xl=self.Norm(x*xy)\n",
    "# #         yl=self.Norm(y*xy)\n",
    "# # #         xyl=self.Norm(xyl)\n",
    "# #         xyl=torch.cat([xl,yl],1)\n",
    "# # #         xyl=inputs*xy\n",
    "# # #         xyl=self.Norm(xyl)\n",
    "#         xyl=self.mlp(xy_m)\n",
    "        \n",
    "#         return torch.sigmoid(xyl)\n",
    "# # #         b, c, _, _ = x.size()\n",
    "# # #         y = self.avg_pool(x).view(b, c)\n",
    "# # #         y = self.fc(y).view(b, c, 1, 1)\n",
    "# # #         return x * y.expand_as(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcfcc2e-4c6b-42af-b0c8-495be8089320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d160c1a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f412f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_number=network[network[4]==1].shape[0]\n",
    "negtive_number=network[network[4]==0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e00796a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio=0.1\n",
    "val_ratio=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27924c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_maks_result= pos_masks(pos_number,negtive_number, test_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "916b7bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_mask=pos_maks_result['pos_masks'][0]\n",
    "test_pos_mask=pos_maks_result['pos_masks'][1]\n",
    "val_pos_mask=pos_maks_result['pos_masks'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e98a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pos_id=pos_maks_result['test_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55fc4436",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_neg_mask,val_neg_mask,train_neg_set=test_val_neg_maks(pos_number,negtive_number,test_ratio,val_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a43e1e-357c-436b-a6df-c37dbf80b8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fdb6aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neg_mask_build(pos_number,negtive_number,train_neg_set,train_size):\n",
    "#     train_size = pos_number - (test_ratio+val_ratio)\n",
    "    train_neg_id=np.random.permutation(train_neg_set)\n",
    "    train_neg_id=train_neg_id[:train_size]\n",
    "    \n",
    "    train_neg_mask=np.full((pos_number+negtive_number), False)\n",
    "    train_neg_mask[train_neg_id]=True    \n",
    "    \n",
    "    return train_neg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6907fbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_neg_set=np.random.permutation(train_neg_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2388681f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg_sets==np.array_split(train_neg_set,3)\n",
    "# neg_sets=train_neg_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b74a491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_neg_set=neg_sets[neg_sub_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9696823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_neg_test=train_neg_set[:int(pos_number*val_ratio)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6397cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_neg_set=train_neg_set[int(pos_number*val_ratio):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "384a1779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_neg_mask=np.full((pos_number+negtive_number), False)\n",
    "# val_neg_mask[val_neg_test]=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a215d411",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = pos_maks_result['train_size']\n",
    "# train_neg_mask=train_neg_mask_build(pos_number,negtive_number,train_neg_set,train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1bf0273",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "weight_decay=0.\n",
    "in_feats=input_x.shape[1]\n",
    "n_hidden=128\n",
    "out_dim=1\n",
    "# n_layers=1\n",
    "# norm=None\n",
    "# activation=F.relu\n",
    "# dropout=0.\n",
    "# aggregator_type='pool'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dbc23602",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=fusion1(in_feats,n_hidden,out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a242ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9110eb26-096e-4dca-adc3-7d96114485e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "600d2054",
   "metadata": {},
   "outputs": [],
   "source": [
    "patience = 20\n",
    "early_stopping = EarlyStopping(patience,path='conv.pt', verbose=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4adcc14b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, train_loss: 0.6914793848991394,val_loss:0.6926318407058716,val_acc:0.5271715323765106\n",
      "In epoch 5, train_loss: 0.6342646479606628,val_loss:0.6226556897163391,val_acc:0.7292509469452962\n",
      "In epoch 10, train_loss: 0.6004579663276672,val_loss:0.5817379355430603,val_acc:0.7730874281738773\n",
      "In epoch 15, train_loss: 0.5710968375205994,val_loss:0.5449512004852295,val_acc:0.8154422943131747\n",
      "In epoch 20, train_loss: 0.5428081750869751,val_loss:0.515661358833313,val_acc:0.8335888582545286\n",
      "In epoch 25, train_loss: 0.5183410048484802,val_loss:0.5003213882446289,val_acc:0.8409067484346414\n",
      "In epoch 30, train_loss: 0.49506819248199463,val_loss:0.48694103956222534,val_acc:0.8492939782009328\n",
      "In epoch 35, train_loss: 0.4684229791164398,val_loss:0.4806852638721466,val_acc:0.8501765054497668\n",
      "In epoch 40, train_loss: 0.4379933178424835,val_loss:0.4739850163459778,val_acc:0.8542734932618723\n",
      "In epoch 45, train_loss: 0.4236830174922943,val_loss:0.46593567728996277,val_acc:0.8590404287665232\n",
      "In epoch 50, train_loss: 0.40192046761512756,val_loss:0.4644233286380768,val_acc:0.8594269370506841\n",
      "In epoch 55, train_loss: 0.3894422650337219,val_loss:0.465014785528183,val_acc:0.8649475637094488\n",
      "In epoch 60, train_loss: 0.3841657340526581,val_loss:0.46269920468330383,val_acc:0.8640457110464068\n",
      "In epoch 65, train_loss: 0.3693549931049347,val_loss:0.4652651846408844,val_acc:0.8707709551908063\n",
      "In epoch 70, train_loss: 0.34201887249946594,val_loss:0.4750021994113922,val_acc:0.863723620809606\n",
      "In epoch 75, train_loss: 0.3352675437927246,val_loss:0.4588417410850525,val_acc:0.8735924656651807\n",
      "In epoch 80, train_loss: 0.3183061182498932,val_loss:0.4751952886581421,val_acc:0.8692313638588988\n",
      "Early stopping\n",
      "tensor(0.6036)\n",
      "0.8278943028678916\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1000000):\n",
    "    model.train()\n",
    "    \n",
    "    train_neg_mask=train_neg_mask_build(pos_number,negtive_number,train_neg_set,train_size)\n",
    "    \n",
    "    logits = model(input_x,input_y,inputs)\n",
    "#     loss,train_acc = compute_loss(logits[train_pos_mask],logits[train_neg_mask])\n",
    "    loss= binary_loss(logits[train_pos_mask].view(-1),logits[train_neg_mask].view(-1))\n",
    "    \n",
    "    val_loss,acc = binary_val3(model,input_x,input_y,inputs,val_pos_mask,val_neg_mask)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "#     scheduler.step()\n",
    "    if epoch % 5 == 0:\n",
    "        print('In epoch {}, train_loss: {},val_loss:{},val_acc:{}'.format(epoch, loss,val_loss,acc))\n",
    "#         print('In epoch {}, train_loss: {}, train_acc:{},val_loss:{},val_acc:{}'.format(epoch, loss,train_acc,val_loss,acc))\n",
    "    early_stopping(val_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print  (\"Early stopping\")\n",
    "        break \n",
    "with torch.no_grad():\n",
    "#     model.load_state_dict(torch.load('dot_dnn.pt')) \n",
    "    pred = model(input_x,input_y,inputs)\n",
    "#     test_loss, test_acc=compute_loss(pred[test_pos_mask],pred[test_neg_mask])\n",
    "    test_loss=binary_loss(pred[test_pos_mask].view(-1),pred[test_neg_mask].view(-1))\n",
    "    test_acc=compute_auc(pred[test_pos_mask].view(-1),pred[test_neg_mask].view(-1))\n",
    "    print(test_loss)\n",
    "    print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47712772",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with torch.no_grad():\n",
    "#     model.load_state_dict(torch.load('conv.pt')) \n",
    "#     pred = model(input_x,input_y,inputs)\n",
    "# #     test_loss, test_acc=compute_loss(pred[test_pos_mask],pred[test_neg_mask])\n",
    "#     test_loss=binary_loss(pred[test_pos_mask].view(-1),pred[test_neg_mask].view(-1))\n",
    "#     test_acc=compute_auc(pred[test_pos_mask].view(-1),pred[test_neg_mask].view(-1))\n",
    "#     print(test_loss)\n",
    "#     print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c5b84f2-c569-4513-b1f7-ecc9d8efa7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1d013369-1e1c-4aab-b4a7-08a7d005eeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "#     model.load_state_dict(torch.load('dot_dnn.pt')) \n",
    "    pred = model(input_x,input_y,inputs)\n",
    "#     test_loss, test_acc=compute_loss(pred[test_pos_mask],pred[test_neg_mask])\n",
    "    pos_logits,neg_logits=pred[test_pos_mask].view(-1),pred[test_neg_mask].view(-1)\n",
    "    pre = torch.cat([pos_logits, neg_logits])\n",
    "    labels = torch.cat([torch.ones(pos_logits.shape[0]), torch.zeros(neg_logits.shape[0])])\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(labels, pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e910ee22-714a-4700-a142-9dab724f2157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50063532, 0.5       , 0.50063694, 0.50127551, 0.50191571,\n",
       "       0.50255754, 0.50320102, 0.50384615, 0.50449294, 0.50514139,\n",
       "       0.50579151, 0.5064433 , 0.50709677, 0.50775194, 0.5084088 ,\n",
       "       0.50906736, 0.50972763, 0.51038961, 0.51105332, 0.51171875,\n",
       "       0.51238592, 0.51305483, 0.5124183 , 0.5117801 , 0.51245085,\n",
       "       0.51312336, 0.51379763, 0.51447368, 0.51515152, 0.51583113,\n",
       "       0.51651255, 0.51719577, 0.51655629, 0.51724138, 0.51792829,\n",
       "       0.51861702, 0.51930759, 0.52      , 0.52069426, 0.52139037,\n",
       "       0.52208835, 0.5227882 , 0.52214765, 0.52284946, 0.52355316,\n",
       "       0.52425876, 0.52496626, 0.52567568, 0.52638701, 0.52710027,\n",
       "       0.52781547, 0.52853261, 0.5292517 , 0.52997275, 0.53069577,\n",
       "       0.53142077, 0.53214774, 0.53287671, 0.53360768, 0.53434066,\n",
       "       0.53507565, 0.53581267, 0.53655172, 0.53729282, 0.53803596,\n",
       "       0.53878116, 0.53952843, 0.54027778, 0.54102921, 0.54178273,\n",
       "       0.54253835, 0.54329609, 0.54405594, 0.54481793, 0.54558205,\n",
       "       0.54634831, 0.54711674, 0.54788732, 0.54866008, 0.54943503,\n",
       "       0.55021216, 0.5509915 , 0.55177305, 0.55255682, 0.55334282,\n",
       "       0.55413105, 0.55492154, 0.55571429, 0.5565093 , 0.55730659,\n",
       "       0.55810617, 0.55890805, 0.55971223, 0.55907781, 0.55988456,\n",
       "       0.56069364, 0.56150507, 0.56086957, 0.5616836 , 0.5625    ,\n",
       "       0.56331878, 0.56413994, 0.5649635 , 0.56432749, 0.56515373,\n",
       "       0.5659824 , 0.56681351, 0.56764706, 0.56848306, 0.56784661,\n",
       "       0.56868538, 0.56952663, 0.57037037, 0.57121662, 0.57206538,\n",
       "       0.57291667, 0.57377049, 0.57462687, 0.5754858 , 0.57634731,\n",
       "       0.57721139, 0.57807808, 0.57894737, 0.57831325, 0.57918552,\n",
       "       0.57854985, 0.57942511, 0.58030303, 0.58118361, 0.58206687,\n",
       "       0.58143075, 0.58231707, 0.58320611, 0.58409786, 0.58499234,\n",
       "       0.58435583, 0.58525346, 0.58615385, 0.58551618, 0.58641975,\n",
       "       0.58732612, 0.58823529, 0.5875969 , 0.58695652, 0.58786936,\n",
       "       0.58878505, 0.58970359, 0.590625  , 0.5915493 , 0.59247649,\n",
       "       0.59340659, 0.59433962, 0.59527559, 0.59621451, 0.59557662,\n",
       "       0.59651899, 0.59746434, 0.5984127 , 0.59936407, 0.60031847,\n",
       "       0.59968102, 0.60063898, 0.6016    , 0.6025641 , 0.6035313 ,\n",
       "       0.60450161, 0.60547504, 0.60645161, 0.60743134, 0.60841424,\n",
       "       0.60940032, 0.61038961, 0.61138211, 0.61074919, 0.61174551,\n",
       "       0.6127451 , 0.61374795, 0.6147541 , 0.61412151, 0.61348684,\n",
       "       0.61449753, 0.61551155, 0.61652893, 0.61754967, 0.6185738 ,\n",
       "       0.6179402 , 0.61896839, 0.62      , 0.61936561, 0.62040134,\n",
       "       0.62144054, 0.62248322, 0.62184874, 0.62289562, 0.62394604,\n",
       "       0.62331081, 0.62436548, 0.62542373, 0.62648557, 0.62755102,\n",
       "       0.6286201 , 0.62969283, 0.63076923, 0.63184932, 0.63121784,\n",
       "       0.63230241, 0.63339071, 0.63448276, 0.63557858, 0.6366782 ,\n",
       "       0.63604853, 0.63715278, 0.63826087, 0.63763066, 0.63699825,\n",
       "       0.63811189, 0.63747811, 0.63859649, 0.63796134, 0.63908451,\n",
       "       0.64021164, 0.63957597, 0.64070796, 0.64184397, 0.64298401,\n",
       "       0.64234875, 0.64349376, 0.64464286, 0.64579606, 0.64695341,\n",
       "       0.64631957, 0.64748201, 0.64864865, 0.64981949, 0.65099458,\n",
       "       0.65217391, 0.65154265, 0.65272727, 0.65391621, 0.65328467,\n",
       "       0.65265082, 0.65384615, 0.65321101, 0.65257353, 0.65377532,\n",
       "       0.65498155, 0.65434381, 0.6537037 , 0.65306122, 0.65427509,\n",
       "       0.65363128, 0.65485075, 0.65607477, 0.65730337, 0.65853659,\n",
       "       0.65789474, 0.65913371, 0.65849057, 0.65973535, 0.66098485,\n",
       "       0.66223909, 0.6634981 , 0.6647619 , 0.66603053, 0.66730402,\n",
       "       0.66858238, 0.66986564, 0.67115385, 0.67244701, 0.67374517,\n",
       "       0.67504836, 0.67635659, 0.67572816, 0.6770428 , 0.67641326,\n",
       "       0.67578125, 0.67710372, 0.67843137, 0.67976424, 0.67913386,\n",
       "       0.68047337, 0.6798419 , 0.67920792, 0.68055556, 0.68190855,\n",
       "       0.6812749 , 0.68263473, 0.684     , 0.68537074, 0.68674699,\n",
       "       0.68812877, 0.6875    , 0.68888889, 0.68825911, 0.68965517,\n",
       "       0.68902439, 0.6904277 , 0.69183673, 0.69120654, 0.69262295,\n",
       "       0.69404517, 0.69341564, 0.69484536, 0.69421488, 0.69358178,\n",
       "       0.69502075, 0.6964657 , 0.69791667, 0.6993737 , 0.70083682,\n",
       "       0.70230608, 0.70378151, 0.70526316, 0.70675105, 0.70613108,\n",
       "       0.70550847, 0.70488323, 0.70638298, 0.70575693, 0.70726496,\n",
       "       0.70877944, 0.70815451, 0.70967742, 0.7112069 , 0.71274298,\n",
       "       0.71428571, 0.71366594, 0.71521739, 0.7167756 , 0.71615721,\n",
       "       0.71553611, 0.71491228, 0.71428571, 0.71365639, 0.71302428,\n",
       "       0.71460177, 0.71396896, 0.71333333, 0.71269488, 0.71205357,\n",
       "       0.7114094 , 0.71076233, 0.71011236, 0.71171171, 0.71331828,\n",
       "       0.71493213, 0.71655329, 0.71818182, 0.71981777, 0.72146119,\n",
       "       0.72311213, 0.72477064, 0.72413793, 0.72580645, 0.72517321,\n",
       "       0.72685185, 0.7262181 , 0.7255814 , 0.72727273, 0.72663551,\n",
       "       0.72599532, 0.72535211, 0.72470588, 0.72641509, 0.72576832,\n",
       "       0.72511848, 0.72446556, 0.72619048, 0.72553699, 0.72727273,\n",
       "       0.72901679, 0.72836538, 0.73012048, 0.7294686 , 0.73123487,\n",
       "       0.73300971, 0.7323601 , 0.73414634, 0.73349633, 0.73529412,\n",
       "       0.73464373, 0.73399015, 0.73580247, 0.73762376, 0.73945409,\n",
       "       0.73880597, 0.74064838, 0.7425    , 0.74185464, 0.74120603,\n",
       "       0.74307305, 0.74494949, 0.7443038 , 0.74619289, 0.74554707,\n",
       "       0.74489796, 0.74424552, 0.74615385, 0.74550129, 0.74742268,\n",
       "       0.74677003, 0.74870466, 0.74805195, 0.75      , 0.75195822,\n",
       "       0.7513089 , 0.75065617, 0.75263158, 0.75461741, 0.75396825,\n",
       "       0.75331565, 0.75265957, 0.75466667, 0.7540107 , 0.75335121,\n",
       "       0.75537634, 0.75471698, 0.75405405, 0.75609756, 0.75815217,\n",
       "       0.75749319, 0.75956284, 0.76164384, 0.76098901, 0.76033058,\n",
       "       0.76243094, 0.76454294, 0.76388889, 0.76601671, 0.76815642,\n",
       "       0.767507  , 0.76966292, 0.76901408, 0.77118644, 0.77053824,\n",
       "       0.77272727, 0.77207977, 0.77428571, 0.7765043 , 0.77873563,\n",
       "       0.78097983, 0.78323699, 0.7826087 , 0.78197674, 0.78425656,\n",
       "       0.78362573, 0.7829912 , 0.78529412, 0.78466077, 0.78698225,\n",
       "       0.78931751, 0.79166667, 0.79402985, 0.79341317, 0.7957958 ,\n",
       "       0.79518072, 0.79758308, 0.7969697 , 0.79635258, 0.79878049,\n",
       "       0.80122324, 0.80368098, 0.80307692, 0.80246914, 0.80185759,\n",
       "       0.80434783, 0.80685358, 0.809375  , 0.81191223, 0.81132075,\n",
       "       0.81072555, 0.81012658, 0.81269841, 0.81210191, 0.8115016 ,\n",
       "       0.81410256, 0.81350482, 0.81612903, 0.81877023, 0.82142857,\n",
       "       0.82410423, 0.82352941, 0.82295082, 0.82565789, 0.82508251,\n",
       "       0.82450331, 0.82392027, 0.82333333, 0.82274247, 0.82550336,\n",
       "       0.82491582, 0.8277027 , 0.82711864, 0.82653061, 0.82593857,\n",
       "       0.82534247, 0.82817869, 0.83103448, 0.83044983, 0.83333333,\n",
       "       0.83275261, 0.83566434, 0.83859649, 0.83802817, 0.83745583,\n",
       "       0.83687943, 0.83629893, 0.83928571, 0.83870968, 0.8381295 ,\n",
       "       0.83754513, 0.83695652, 0.83636364, 0.83576642, 0.83516484,\n",
       "       0.83455882, 0.83394834, 0.83333333, 0.83271375, 0.83208955,\n",
       "       0.83520599, 0.83458647, 0.83396226, 0.83333333, 0.83269962,\n",
       "       0.83587786, 0.83524904, 0.83461538, 0.83397683, 0.83333333,\n",
       "       0.83268482, 0.83203125, 0.83137255, 0.83070866, 0.83003953,\n",
       "       0.83333333, 0.83266932, 0.832     , 0.8313253 , 0.83064516,\n",
       "       0.82995951, 0.82926829, 0.82857143, 0.82786885, 0.82716049,\n",
       "       0.82644628, 0.82987552, 0.82916667, 0.82845188, 0.82773109,\n",
       "       0.83122363, 0.83050847, 0.82978723, 0.82905983, 0.82832618,\n",
       "       0.82758621, 0.82683983, 0.82608696, 0.82969432, 0.83333333,\n",
       "       0.83259912, 0.83185841, 0.83111111, 0.83482143, 0.83408072,\n",
       "       0.83333333, 0.83257919, 0.83636364, 0.83561644, 0.83486239,\n",
       "       0.83410138, 0.83796296, 0.8372093 , 0.8364486 , 0.83568075,\n",
       "       0.83490566, 0.83412322, 0.83333333, 0.83732057, 0.84134615,\n",
       "       0.84057971, 0.83980583, 0.84390244, 0.84803922, 0.84729064,\n",
       "       0.84653465, 0.85074627, 0.855     , 0.85427136, 0.85858586,\n",
       "       0.85786802, 0.85714286, 0.85641026, 0.8556701 , 0.85492228,\n",
       "       0.859375  , 0.86387435, 0.86315789, 0.86243386, 0.86170213,\n",
       "       0.86096257, 0.86021505, 0.85945946, 0.86413043, 0.86338798,\n",
       "       0.86263736, 0.86740331, 0.86666667, 0.87150838, 0.87640449,\n",
       "       0.87570621, 0.875     , 0.87428571, 0.87356322, 0.87283237,\n",
       "       0.87790698, 0.88304094, 0.88235294, 0.8816568 , 0.88095238,\n",
       "       0.88023952, 0.87951807, 0.87878788, 0.87804878, 0.87730061,\n",
       "       0.87654321, 0.8757764 , 0.88125   , 0.88050314, 0.87974684,\n",
       "       0.87898089, 0.88461538, 0.88387097, 0.88311688, 0.88235294,\n",
       "       0.88157895, 0.8807947 , 0.88666667, 0.88590604, 0.88513514,\n",
       "       0.88435374, 0.88356164, 0.88275862, 0.88194444, 0.88111888,\n",
       "       0.88028169, 0.87943262, 0.87857143, 0.87769784, 0.88405797,\n",
       "       0.88321168, 0.88235294, 0.88148148, 0.88059701, 0.87969925,\n",
       "       0.87878788, 0.88549618, 0.88461538, 0.88372093, 0.8828125 ,\n",
       "       0.88976378, 0.88888889, 0.896     , 0.89516129, 0.89430894,\n",
       "       0.89344262, 0.89256198, 0.9       , 0.89915966, 0.89830508,\n",
       "       0.8974359 , 0.89655172, 0.89565217, 0.89473684, 0.90265487,\n",
       "       0.90178571, 0.9009009 , 0.9       , 0.89908257, 0.89814815,\n",
       "       0.90654206, 0.90566038, 0.91428571, 0.91346154, 0.91262136,\n",
       "       0.91176471, 0.91089109, 0.92      , 0.91919192, 0.91836735,\n",
       "       0.91752577, 0.91666667, 0.91578947, 0.91489362, 0.91397849,\n",
       "       0.91304348, 0.91208791, 0.92222222, 0.92134831, 0.93181818,\n",
       "       0.93103448, 0.93023256, 0.92941176, 0.92857143, 0.92771084,\n",
       "       0.93902439, 0.9382716 , 0.9375    , 0.93670886, 0.93589744,\n",
       "       0.93506494, 0.94736842, 0.94666667, 0.94594595, 0.94520548,\n",
       "       0.94444444, 0.94366197, 0.94285714, 0.94202899, 0.94117647,\n",
       "       0.94029851, 0.93939394, 0.93846154, 0.9375    , 0.93650794,\n",
       "       0.93548387, 0.93442623, 0.93333333, 0.93220339, 0.93103448,\n",
       "       0.94736842, 0.94642857, 0.94545455, 0.94444444, 0.94339623,\n",
       "       0.94230769, 0.94117647, 0.94      , 0.93877551, 0.9375    ,\n",
       "       0.93617021, 0.93478261, 0.93333333, 0.93181818, 0.93023256,\n",
       "       0.92857143, 0.92682927, 0.95      , 0.94871795, 0.94736842,\n",
       "       0.94594595, 0.94444444, 0.94285714, 0.94117647, 0.93939394,\n",
       "       0.9375    , 0.93548387, 0.93333333, 0.93103448, 0.92857143,\n",
       "       0.92592593, 0.92307692, 0.92      , 0.91666667, 0.91304348,\n",
       "       0.90909091, 0.95238095, 0.95      , 0.94736842, 0.94444444,\n",
       "       0.94117647, 0.9375    , 0.93333333, 0.92857143, 0.92307692,\n",
       "       0.91666667, 0.90909091, 0.9       , 0.88888889, 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5adb2ade-3769-4c7c-9c80-32bea94bd184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.99746193, 0.99746193, 0.99746193, 0.99746193,\n",
       "       0.99746193, 0.99746193, 0.99746193, 0.99746193, 0.99746193,\n",
       "       0.99746193, 0.99746193, 0.99746193, 0.99746193, 0.99746193,\n",
       "       0.99746193, 0.99746193, 0.99746193, 0.99746193, 0.99746193,\n",
       "       0.99746193, 0.99746193, 0.99492386, 0.99238579, 0.99238579,\n",
       "       0.99238579, 0.99238579, 0.99238579, 0.99238579, 0.99238579,\n",
       "       0.99238579, 0.99238579, 0.98984772, 0.98984772, 0.98984772,\n",
       "       0.98984772, 0.98984772, 0.98984772, 0.98984772, 0.98984772,\n",
       "       0.98984772, 0.98984772, 0.98730964, 0.98730964, 0.98730964,\n",
       "       0.98730964, 0.98730964, 0.98730964, 0.98730964, 0.98730964,\n",
       "       0.98730964, 0.98730964, 0.98730964, 0.98730964, 0.98730964,\n",
       "       0.98730964, 0.98730964, 0.98730964, 0.98730964, 0.98730964,\n",
       "       0.98730964, 0.98730964, 0.98730964, 0.98730964, 0.98730964,\n",
       "       0.98730964, 0.98730964, 0.98730964, 0.98730964, 0.98730964,\n",
       "       0.98730964, 0.98730964, 0.98730964, 0.98730964, 0.98730964,\n",
       "       0.98730964, 0.98730964, 0.98730964, 0.98730964, 0.98730964,\n",
       "       0.98730964, 0.98730964, 0.98730964, 0.98730964, 0.98730964,\n",
       "       0.98730964, 0.98730964, 0.98730964, 0.98730964, 0.98730964,\n",
       "       0.98730964, 0.98730964, 0.98730964, 0.98477157, 0.98477157,\n",
       "       0.98477157, 0.98477157, 0.9822335 , 0.9822335 , 0.9822335 ,\n",
       "       0.9822335 , 0.9822335 , 0.9822335 , 0.97969543, 0.97969543,\n",
       "       0.97969543, 0.97969543, 0.97969543, 0.97969543, 0.97715736,\n",
       "       0.97715736, 0.97715736, 0.97715736, 0.97715736, 0.97715736,\n",
       "       0.97715736, 0.97715736, 0.97715736, 0.97715736, 0.97715736,\n",
       "       0.97715736, 0.97715736, 0.97715736, 0.97461929, 0.97461929,\n",
       "       0.97208122, 0.97208122, 0.97208122, 0.97208122, 0.97208122,\n",
       "       0.96954315, 0.96954315, 0.96954315, 0.96954315, 0.96954315,\n",
       "       0.96700508, 0.96700508, 0.96700508, 0.96446701, 0.96446701,\n",
       "       0.96446701, 0.96446701, 0.96192893, 0.95939086, 0.95939086,\n",
       "       0.95939086, 0.95939086, 0.95939086, 0.95939086, 0.95939086,\n",
       "       0.95939086, 0.95939086, 0.95939086, 0.95939086, 0.95685279,\n",
       "       0.95685279, 0.95685279, 0.95685279, 0.95685279, 0.95685279,\n",
       "       0.95431472, 0.95431472, 0.95431472, 0.95431472, 0.95431472,\n",
       "       0.95431472, 0.95431472, 0.95431472, 0.95431472, 0.95431472,\n",
       "       0.95431472, 0.95431472, 0.95431472, 0.95177665, 0.95177665,\n",
       "       0.95177665, 0.95177665, 0.95177665, 0.94923858, 0.94670051,\n",
       "       0.94670051, 0.94670051, 0.94670051, 0.94670051, 0.94670051,\n",
       "       0.94416244, 0.94416244, 0.94416244, 0.94162437, 0.94162437,\n",
       "       0.94162437, 0.94162437, 0.93908629, 0.93908629, 0.93908629,\n",
       "       0.93654822, 0.93654822, 0.93654822, 0.93654822, 0.93654822,\n",
       "       0.93654822, 0.93654822, 0.93654822, 0.93654822, 0.93401015,\n",
       "       0.93401015, 0.93401015, 0.93401015, 0.93401015, 0.93401015,\n",
       "       0.93147208, 0.93147208, 0.93147208, 0.92893401, 0.92639594,\n",
       "       0.92639594, 0.92385787, 0.92385787, 0.9213198 , 0.9213198 ,\n",
       "       0.9213198 , 0.91878173, 0.91878173, 0.91878173, 0.91878173,\n",
       "       0.91624365, 0.91624365, 0.91624365, 0.91624365, 0.91624365,\n",
       "       0.91370558, 0.91370558, 0.91370558, 0.91370558, 0.91370558,\n",
       "       0.91370558, 0.91116751, 0.91116751, 0.91116751, 0.90862944,\n",
       "       0.90609137, 0.90609137, 0.9035533 , 0.90101523, 0.90101523,\n",
       "       0.90101523, 0.89847716, 0.89593909, 0.89340102, 0.89340102,\n",
       "       0.89086294, 0.89086294, 0.89086294, 0.89086294, 0.89086294,\n",
       "       0.88832487, 0.88832487, 0.8857868 , 0.8857868 , 0.8857868 ,\n",
       "       0.8857868 , 0.8857868 , 0.8857868 , 0.8857868 , 0.8857868 ,\n",
       "       0.8857868 , 0.8857868 , 0.8857868 , 0.8857868 , 0.8857868 ,\n",
       "       0.8857868 , 0.8857868 , 0.88324873, 0.88324873, 0.88071066,\n",
       "       0.87817259, 0.87817259, 0.87817259, 0.87817259, 0.87563452,\n",
       "       0.87563452, 0.87309645, 0.87055838, 0.87055838, 0.87055838,\n",
       "       0.8680203 , 0.8680203 , 0.8680203 , 0.8680203 , 0.8680203 ,\n",
       "       0.8680203 , 0.86548223, 0.86548223, 0.86294416, 0.86294416,\n",
       "       0.86040609, 0.86040609, 0.86040609, 0.85786802, 0.85786802,\n",
       "       0.85786802, 0.85532995, 0.85532995, 0.85279188, 0.85025381,\n",
       "       0.85025381, 0.85025381, 0.85025381, 0.85025381, 0.85025381,\n",
       "       0.85025381, 0.85025381, 0.85025381, 0.85025381, 0.84771574,\n",
       "       0.84517766, 0.84263959, 0.84263959, 0.84010152, 0.84010152,\n",
       "       0.84010152, 0.83756345, 0.83756345, 0.83756345, 0.83756345,\n",
       "       0.83756345, 0.83502538, 0.83502538, 0.83502538, 0.83248731,\n",
       "       0.82994924, 0.82741117, 0.8248731 , 0.82233503, 0.81979695,\n",
       "       0.81979695, 0.81725888, 0.81472081, 0.81218274, 0.80964467,\n",
       "       0.8071066 , 0.80456853, 0.80203046, 0.80203046, 0.80203046,\n",
       "       0.80203046, 0.80203046, 0.80203046, 0.80203046, 0.80203046,\n",
       "       0.80203046, 0.80203046, 0.79949239, 0.79949239, 0.79695431,\n",
       "       0.79695431, 0.79441624, 0.79187817, 0.79187817, 0.7893401 ,\n",
       "       0.78680203, 0.78426396, 0.78172589, 0.78172589, 0.77918782,\n",
       "       0.77664975, 0.77411168, 0.77411168, 0.7715736 , 0.7715736 ,\n",
       "       0.7715736 , 0.76903553, 0.76903553, 0.76649746, 0.76649746,\n",
       "       0.76649746, 0.76395939, 0.76395939, 0.76142132, 0.76142132,\n",
       "       0.75888325, 0.75634518, 0.75634518, 0.75634518, 0.75634518,\n",
       "       0.75380711, 0.75380711, 0.75380711, 0.75126904, 0.74873096,\n",
       "       0.74873096, 0.74873096, 0.74619289, 0.74619289, 0.74365482,\n",
       "       0.74111675, 0.73857868, 0.73857868, 0.73604061, 0.73604061,\n",
       "       0.73350254, 0.73350254, 0.73096447, 0.73096447, 0.73096447,\n",
       "       0.7284264 , 0.72588832, 0.72588832, 0.72588832, 0.72335025,\n",
       "       0.72081218, 0.71827411, 0.71827411, 0.71573604, 0.71319797,\n",
       "       0.71319797, 0.7106599 , 0.70812183, 0.70812183, 0.70812183,\n",
       "       0.70558376, 0.70558376, 0.70558376, 0.70304569, 0.70050761,\n",
       "       0.70050761, 0.70050761, 0.69796954, 0.69796954, 0.69796954,\n",
       "       0.69543147, 0.69543147, 0.6928934 , 0.6928934 , 0.69035533,\n",
       "       0.69035533, 0.68781726, 0.68781726, 0.68781726, 0.68781726,\n",
       "       0.68781726, 0.68781726, 0.68527919, 0.68274112, 0.68274112,\n",
       "       0.68020305, 0.67766497, 0.67766497, 0.6751269 , 0.6751269 ,\n",
       "       0.6751269 , 0.6751269 , 0.6751269 , 0.67258883, 0.67258883,\n",
       "       0.67005076, 0.67005076, 0.66751269, 0.66497462, 0.66497462,\n",
       "       0.66497462, 0.66497462, 0.66243655, 0.65989848, 0.65736041,\n",
       "       0.65736041, 0.65736041, 0.65736041, 0.65736041, 0.65482234,\n",
       "       0.65228426, 0.64974619, 0.64974619, 0.64720812, 0.64467005,\n",
       "       0.64467005, 0.64213198, 0.64213198, 0.64213198, 0.64213198,\n",
       "       0.64213198, 0.63959391, 0.63705584, 0.63705584, 0.63451777,\n",
       "       0.6319797 , 0.62944162, 0.62690355, 0.62436548, 0.62436548,\n",
       "       0.62182741, 0.62182741, 0.61928934, 0.61675127, 0.6142132 ,\n",
       "       0.61167513, 0.61167513, 0.61167513, 0.60913706, 0.60913706,\n",
       "       0.60659898, 0.60659898, 0.60659898, 0.60406091, 0.60152284,\n",
       "       0.59898477, 0.5964467 , 0.5964467 , 0.59390863, 0.59137056,\n",
       "       0.58883249, 0.58629442, 0.58375635, 0.58121827, 0.5786802 ,\n",
       "       0.57614213, 0.57360406, 0.57106599, 0.56852792, 0.56598985,\n",
       "       0.56598985, 0.56345178, 0.56091371, 0.55837563, 0.55583756,\n",
       "       0.55583756, 0.55329949, 0.55076142, 0.54822335, 0.54568528,\n",
       "       0.54314721, 0.54060914, 0.53807107, 0.53553299, 0.53299492,\n",
       "       0.53299492, 0.53045685, 0.52791878, 0.52538071, 0.52284264,\n",
       "       0.52030457, 0.5177665 , 0.51522843, 0.51269036, 0.51015228,\n",
       "       0.50761421, 0.50761421, 0.50507614, 0.50253807, 0.5       ,\n",
       "       0.5       , 0.49746193, 0.49492386, 0.49238579, 0.48984772,\n",
       "       0.48730964, 0.48477157, 0.4822335 , 0.4822335 , 0.4822335 ,\n",
       "       0.47969543, 0.47715736, 0.47461929, 0.47461929, 0.47208122,\n",
       "       0.46954315, 0.46700508, 0.46700508, 0.46446701, 0.46192893,\n",
       "       0.45939086, 0.45939086, 0.45685279, 0.45431472, 0.45177665,\n",
       "       0.44923858, 0.44670051, 0.44416244, 0.44416244, 0.44416244,\n",
       "       0.44162437, 0.43908629, 0.43908629, 0.43908629, 0.43654822,\n",
       "       0.43401015, 0.43401015, 0.43401015, 0.43147208, 0.43147208,\n",
       "       0.42893401, 0.42639594, 0.42385787, 0.4213198 , 0.41878173,\n",
       "       0.41878173, 0.41878173, 0.41624365, 0.41370558, 0.41116751,\n",
       "       0.40862944, 0.40609137, 0.4035533 , 0.4035533 , 0.40101523,\n",
       "       0.39847716, 0.39847716, 0.39593909, 0.39593909, 0.39593909,\n",
       "       0.39340102, 0.39086294, 0.38832487, 0.3857868 , 0.38324873,\n",
       "       0.38324873, 0.38324873, 0.38071066, 0.37817259, 0.37563452,\n",
       "       0.37309645, 0.37055838, 0.3680203 , 0.36548223, 0.36294416,\n",
       "       0.36040609, 0.35786802, 0.35786802, 0.35532995, 0.35279188,\n",
       "       0.35025381, 0.35025381, 0.34771574, 0.34517766, 0.34263959,\n",
       "       0.34010152, 0.33756345, 0.33756345, 0.33502538, 0.33248731,\n",
       "       0.32994924, 0.32741117, 0.3248731 , 0.32233503, 0.31979695,\n",
       "       0.31725888, 0.31472081, 0.31218274, 0.30964467, 0.30964467,\n",
       "       0.3071066 , 0.30456853, 0.30203046, 0.29949239, 0.29695431,\n",
       "       0.29441624, 0.29441624, 0.29187817, 0.2893401 , 0.28680203,\n",
       "       0.28680203, 0.28426396, 0.28426396, 0.28172589, 0.27918782,\n",
       "       0.27664975, 0.27411168, 0.27411168, 0.2715736 , 0.26903553,\n",
       "       0.26649746, 0.26395939, 0.26142132, 0.25888325, 0.25888325,\n",
       "       0.25634518, 0.25380711, 0.25126904, 0.24873096, 0.24619289,\n",
       "       0.24619289, 0.24365482, 0.24365482, 0.24111675, 0.23857868,\n",
       "       0.23604061, 0.23350254, 0.23350254, 0.23096447, 0.2284264 ,\n",
       "       0.22588832, 0.22335025, 0.22081218, 0.21827411, 0.21573604,\n",
       "       0.21319797, 0.2106599 , 0.2106599 , 0.20812183, 0.20812183,\n",
       "       0.20558376, 0.20304569, 0.20050761, 0.19796954, 0.19543147,\n",
       "       0.19543147, 0.1928934 , 0.19035533, 0.18781726, 0.18527919,\n",
       "       0.18274112, 0.18274112, 0.18020305, 0.17766497, 0.1751269 ,\n",
       "       0.17258883, 0.17005076, 0.16751269, 0.16497462, 0.16243655,\n",
       "       0.15989848, 0.15736041, 0.15482234, 0.15228426, 0.14974619,\n",
       "       0.14720812, 0.14467005, 0.14213198, 0.13959391, 0.13705584,\n",
       "       0.13705584, 0.13451777, 0.1319797 , 0.12944162, 0.12690355,\n",
       "       0.12436548, 0.12182741, 0.11928934, 0.11675127, 0.1142132 ,\n",
       "       0.11167513, 0.10913706, 0.10659898, 0.10406091, 0.10152284,\n",
       "       0.09898477, 0.0964467 , 0.0964467 , 0.09390863, 0.09137056,\n",
       "       0.08883249, 0.08629442, 0.08375635, 0.08121827, 0.0786802 ,\n",
       "       0.07614213, 0.07360406, 0.07106599, 0.06852792, 0.06598985,\n",
       "       0.06345178, 0.06091371, 0.05837563, 0.05583756, 0.05329949,\n",
       "       0.05076142, 0.05076142, 0.04822335, 0.04568528, 0.04314721,\n",
       "       0.04060914, 0.03807107, 0.03553299, 0.03299492, 0.03045685,\n",
       "       0.02791878, 0.02538071, 0.02284264, 0.02030457, 0.02030457,\n",
       "       0.0177665 , 0.01522843, 0.01269036, 0.01015228, 0.00761421,\n",
       "       0.00507614, 0.00253807, 0.        ])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7982213-6b7c-4024-be6f-baec9823e583",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_logits,neg_logits=pred[test_pos_mask].view(-1),pred[test_neg_mask].view(-1)\n",
    "pre = torch.cat([pos_logits, neg_logits])\n",
    "labels = torch.cat([torch.ones(pos_logits.shape[0]), torch.zeros(neg_logits.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4995e74f-31c9-46d0-acd1-c8dccab64af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "precision, recall, thresholds = precision_recall_curve(labels, pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d4ada4c-af2d-4f99-9598-f3234360b04e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(788,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "70753b15-edc4-4a34-ae3c-870978de5f3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.50063532, 0.5       , 0.50063694, 0.50127551, 0.50191571,\n",
       "       0.50255754, 0.50320102, 0.50384615, 0.50449294, 0.50514139,\n",
       "       0.50579151, 0.5064433 , 0.50709677, 0.50775194, 0.5084088 ,\n",
       "       0.50906736, 0.50972763, 0.51038961, 0.51105332, 0.51171875,\n",
       "       0.51238592, 0.51305483, 0.5124183 , 0.5117801 , 0.51245085,\n",
       "       0.51312336, 0.51379763, 0.51447368, 0.51515152, 0.51583113,\n",
       "       0.51651255, 0.51719577, 0.51655629, 0.51724138, 0.51792829,\n",
       "       0.51861702, 0.51930759, 0.52      , 0.52069426, 0.52139037,\n",
       "       0.52208835, 0.5227882 , 0.52214765, 0.52284946, 0.52355316,\n",
       "       0.52425876, 0.52496626, 0.52567568, 0.52638701, 0.52710027,\n",
       "       0.52781547, 0.52853261, 0.5292517 , 0.52997275, 0.53069577,\n",
       "       0.53142077, 0.53214774, 0.53287671, 0.53360768, 0.53434066,\n",
       "       0.53507565, 0.53581267, 0.53655172, 0.53729282, 0.53803596,\n",
       "       0.53878116, 0.53952843, 0.54027778, 0.54102921, 0.54178273,\n",
       "       0.54253835, 0.54329609, 0.54405594, 0.54481793, 0.54558205,\n",
       "       0.54634831, 0.54711674, 0.54788732, 0.54866008, 0.54943503,\n",
       "       0.55021216, 0.5509915 , 0.55177305, 0.55255682, 0.55334282,\n",
       "       0.55413105, 0.55492154, 0.55571429, 0.5565093 , 0.55730659,\n",
       "       0.55810617, 0.55890805, 0.55971223, 0.55907781, 0.55988456,\n",
       "       0.56069364, 0.56150507, 0.56086957, 0.5616836 , 0.5625    ,\n",
       "       0.56331878, 0.56413994, 0.5649635 , 0.56432749, 0.56515373,\n",
       "       0.5659824 , 0.56681351, 0.56764706, 0.56848306, 0.56784661,\n",
       "       0.56868538, 0.56952663, 0.57037037, 0.57121662, 0.57206538,\n",
       "       0.57291667, 0.57377049, 0.57462687, 0.5754858 , 0.57634731,\n",
       "       0.57721139, 0.57807808, 0.57894737, 0.57831325, 0.57918552,\n",
       "       0.57854985, 0.57942511, 0.58030303, 0.58118361, 0.58206687,\n",
       "       0.58143075, 0.58231707, 0.58320611, 0.58409786, 0.58499234,\n",
       "       0.58435583, 0.58525346, 0.58615385, 0.58551618, 0.58641975,\n",
       "       0.58732612, 0.58823529, 0.5875969 , 0.58695652, 0.58786936,\n",
       "       0.58878505, 0.58970359, 0.590625  , 0.5915493 , 0.59247649,\n",
       "       0.59340659, 0.59433962, 0.59527559, 0.59621451, 0.59557662,\n",
       "       0.59651899, 0.59746434, 0.5984127 , 0.59936407, 0.60031847,\n",
       "       0.59968102, 0.60063898, 0.6016    , 0.6025641 , 0.6035313 ,\n",
       "       0.60450161, 0.60547504, 0.60645161, 0.60743134, 0.60841424,\n",
       "       0.60940032, 0.61038961, 0.61138211, 0.61074919, 0.61174551,\n",
       "       0.6127451 , 0.61374795, 0.6147541 , 0.61412151, 0.61348684,\n",
       "       0.61449753, 0.61551155, 0.61652893, 0.61754967, 0.6185738 ,\n",
       "       0.6179402 , 0.61896839, 0.62      , 0.61936561, 0.62040134,\n",
       "       0.62144054, 0.62248322, 0.62184874, 0.62289562, 0.62394604,\n",
       "       0.62331081, 0.62436548, 0.62542373, 0.62648557, 0.62755102,\n",
       "       0.6286201 , 0.62969283, 0.63076923, 0.63184932, 0.63121784,\n",
       "       0.63230241, 0.63339071, 0.63448276, 0.63557858, 0.6366782 ,\n",
       "       0.63604853, 0.63715278, 0.63826087, 0.63763066, 0.63699825,\n",
       "       0.63811189, 0.63747811, 0.63859649, 0.63796134, 0.63908451,\n",
       "       0.64021164, 0.63957597, 0.64070796, 0.64184397, 0.64298401,\n",
       "       0.64234875, 0.64349376, 0.64464286, 0.64579606, 0.64695341,\n",
       "       0.64631957, 0.64748201, 0.64864865, 0.64981949, 0.65099458,\n",
       "       0.65217391, 0.65154265, 0.65272727, 0.65391621, 0.65328467,\n",
       "       0.65265082, 0.65384615, 0.65321101, 0.65257353, 0.65377532,\n",
       "       0.65498155, 0.65434381, 0.6537037 , 0.65306122, 0.65427509,\n",
       "       0.65363128, 0.65485075, 0.65607477, 0.65730337, 0.65853659,\n",
       "       0.65789474, 0.65913371, 0.65849057, 0.65973535, 0.66098485,\n",
       "       0.66223909, 0.6634981 , 0.6647619 , 0.66603053, 0.66730402,\n",
       "       0.66858238, 0.66986564, 0.67115385, 0.67244701, 0.67374517,\n",
       "       0.67504836, 0.67635659, 0.67572816, 0.6770428 , 0.67641326,\n",
       "       0.67578125, 0.67710372, 0.67843137, 0.67976424, 0.67913386,\n",
       "       0.68047337, 0.6798419 , 0.67920792, 0.68055556, 0.68190855,\n",
       "       0.6812749 , 0.68263473, 0.684     , 0.68537074, 0.68674699,\n",
       "       0.68812877, 0.6875    , 0.68888889, 0.68825911, 0.68965517,\n",
       "       0.68902439, 0.6904277 , 0.69183673, 0.69120654, 0.69262295,\n",
       "       0.69404517, 0.69341564, 0.69484536, 0.69421488, 0.69358178,\n",
       "       0.69502075, 0.6964657 , 0.69791667, 0.6993737 , 0.70083682,\n",
       "       0.70230608, 0.70378151, 0.70526316, 0.70675105, 0.70613108,\n",
       "       0.70550847, 0.70488323, 0.70638298, 0.70575693, 0.70726496,\n",
       "       0.70877944, 0.70815451, 0.70967742, 0.7112069 , 0.71274298,\n",
       "       0.71428571, 0.71366594, 0.71521739, 0.7167756 , 0.71615721,\n",
       "       0.71553611, 0.71491228, 0.71428571, 0.71365639, 0.71302428,\n",
       "       0.71460177, 0.71396896, 0.71333333, 0.71269488, 0.71205357,\n",
       "       0.7114094 , 0.71076233, 0.71011236, 0.71171171, 0.71331828,\n",
       "       0.71493213, 0.71655329, 0.71818182, 0.71981777, 0.72146119,\n",
       "       0.72311213, 0.72477064, 0.72413793, 0.72580645, 0.72517321,\n",
       "       0.72685185, 0.7262181 , 0.7255814 , 0.72727273, 0.72663551,\n",
       "       0.72599532, 0.72535211, 0.72470588, 0.72641509, 0.72576832,\n",
       "       0.72511848, 0.72446556, 0.72619048, 0.72553699, 0.72727273,\n",
       "       0.72901679, 0.72836538, 0.73012048, 0.7294686 , 0.73123487,\n",
       "       0.73300971, 0.7323601 , 0.73414634, 0.73349633, 0.73529412,\n",
       "       0.73464373, 0.73399015, 0.73580247, 0.73762376, 0.73945409,\n",
       "       0.73880597, 0.74064838, 0.7425    , 0.74185464, 0.74120603,\n",
       "       0.74307305, 0.74494949, 0.7443038 , 0.74619289, 0.74554707,\n",
       "       0.74489796, 0.74424552, 0.74615385, 0.74550129, 0.74742268,\n",
       "       0.74677003, 0.74870466, 0.74805195, 0.75      , 0.75195822,\n",
       "       0.7513089 , 0.75065617, 0.75263158, 0.75461741, 0.75396825,\n",
       "       0.75331565, 0.75265957, 0.75466667, 0.7540107 , 0.75335121,\n",
       "       0.75537634, 0.75471698, 0.75405405, 0.75609756, 0.75815217,\n",
       "       0.75749319, 0.75956284, 0.76164384, 0.76098901, 0.76033058,\n",
       "       0.76243094, 0.76454294, 0.76388889, 0.76601671, 0.76815642,\n",
       "       0.767507  , 0.76966292, 0.76901408, 0.77118644, 0.77053824,\n",
       "       0.77272727, 0.77207977, 0.77428571, 0.7765043 , 0.77873563,\n",
       "       0.78097983, 0.78323699, 0.7826087 , 0.78197674, 0.78425656,\n",
       "       0.78362573, 0.7829912 , 0.78529412, 0.78466077, 0.78698225,\n",
       "       0.78931751, 0.79166667, 0.79402985, 0.79341317, 0.7957958 ,\n",
       "       0.79518072, 0.79758308, 0.7969697 , 0.79635258, 0.79878049,\n",
       "       0.80122324, 0.80368098, 0.80307692, 0.80246914, 0.80185759,\n",
       "       0.80434783, 0.80685358, 0.809375  , 0.81191223, 0.81132075,\n",
       "       0.81072555, 0.81012658, 0.81269841, 0.81210191, 0.8115016 ,\n",
       "       0.81410256, 0.81350482, 0.81612903, 0.81877023, 0.82142857,\n",
       "       0.82410423, 0.82352941, 0.82295082, 0.82565789, 0.82508251,\n",
       "       0.82450331, 0.82392027, 0.82333333, 0.82274247, 0.82550336,\n",
       "       0.82491582, 0.8277027 , 0.82711864, 0.82653061, 0.82593857,\n",
       "       0.82534247, 0.82817869, 0.83103448, 0.83044983, 0.83333333,\n",
       "       0.83275261, 0.83566434, 0.83859649, 0.83802817, 0.83745583,\n",
       "       0.83687943, 0.83629893, 0.83928571, 0.83870968, 0.8381295 ,\n",
       "       0.83754513, 0.83695652, 0.83636364, 0.83576642, 0.83516484,\n",
       "       0.83455882, 0.83394834, 0.83333333, 0.83271375, 0.83208955,\n",
       "       0.83520599, 0.83458647, 0.83396226, 0.83333333, 0.83269962,\n",
       "       0.83587786, 0.83524904, 0.83461538, 0.83397683, 0.83333333,\n",
       "       0.83268482, 0.83203125, 0.83137255, 0.83070866, 0.83003953,\n",
       "       0.83333333, 0.83266932, 0.832     , 0.8313253 , 0.83064516,\n",
       "       0.82995951, 0.82926829, 0.82857143, 0.82786885, 0.82716049,\n",
       "       0.82644628, 0.82987552, 0.82916667, 0.82845188, 0.82773109,\n",
       "       0.83122363, 0.83050847, 0.82978723, 0.82905983, 0.82832618,\n",
       "       0.82758621, 0.82683983, 0.82608696, 0.82969432, 0.83333333,\n",
       "       0.83259912, 0.83185841, 0.83111111, 0.83482143, 0.83408072,\n",
       "       0.83333333, 0.83257919, 0.83636364, 0.83561644, 0.83486239,\n",
       "       0.83410138, 0.83796296, 0.8372093 , 0.8364486 , 0.83568075,\n",
       "       0.83490566, 0.83412322, 0.83333333, 0.83732057, 0.84134615,\n",
       "       0.84057971, 0.83980583, 0.84390244, 0.84803922, 0.84729064,\n",
       "       0.84653465, 0.85074627, 0.855     , 0.85427136, 0.85858586,\n",
       "       0.85786802, 0.85714286, 0.85641026, 0.8556701 , 0.85492228,\n",
       "       0.859375  , 0.86387435, 0.86315789, 0.86243386, 0.86170213,\n",
       "       0.86096257, 0.86021505, 0.85945946, 0.86413043, 0.86338798,\n",
       "       0.86263736, 0.86740331, 0.86666667, 0.87150838, 0.87640449,\n",
       "       0.87570621, 0.875     , 0.87428571, 0.87356322, 0.87283237,\n",
       "       0.87790698, 0.88304094, 0.88235294, 0.8816568 , 0.88095238,\n",
       "       0.88023952, 0.87951807, 0.87878788, 0.87804878, 0.87730061,\n",
       "       0.87654321, 0.8757764 , 0.88125   , 0.88050314, 0.87974684,\n",
       "       0.87898089, 0.88461538, 0.88387097, 0.88311688, 0.88235294,\n",
       "       0.88157895, 0.8807947 , 0.88666667, 0.88590604, 0.88513514,\n",
       "       0.88435374, 0.88356164, 0.88275862, 0.88194444, 0.88111888,\n",
       "       0.88028169, 0.87943262, 0.87857143, 0.87769784, 0.88405797,\n",
       "       0.88321168, 0.88235294, 0.88148148, 0.88059701, 0.87969925,\n",
       "       0.87878788, 0.88549618, 0.88461538, 0.88372093, 0.8828125 ,\n",
       "       0.88976378, 0.88888889, 0.896     , 0.89516129, 0.89430894,\n",
       "       0.89344262, 0.89256198, 0.9       , 0.89915966, 0.89830508,\n",
       "       0.8974359 , 0.89655172, 0.89565217, 0.89473684, 0.90265487,\n",
       "       0.90178571, 0.9009009 , 0.9       , 0.89908257, 0.89814815,\n",
       "       0.90654206, 0.90566038, 0.91428571, 0.91346154, 0.91262136,\n",
       "       0.91176471, 0.91089109, 0.92      , 0.91919192, 0.91836735,\n",
       "       0.91752577, 0.91666667, 0.91578947, 0.91489362, 0.91397849,\n",
       "       0.91304348, 0.91208791, 0.92222222, 0.92134831, 0.93181818,\n",
       "       0.93103448, 0.93023256, 0.92941176, 0.92857143, 0.92771084,\n",
       "       0.93902439, 0.9382716 , 0.9375    , 0.93670886, 0.93589744,\n",
       "       0.93506494, 0.94736842, 0.94666667, 0.94594595, 0.94520548,\n",
       "       0.94444444, 0.94366197, 0.94285714, 0.94202899, 0.94117647,\n",
       "       0.94029851, 0.93939394, 0.93846154, 0.9375    , 0.93650794,\n",
       "       0.93548387, 0.93442623, 0.93333333, 0.93220339, 0.93103448,\n",
       "       0.94736842, 0.94642857, 0.94545455, 0.94444444, 0.94339623,\n",
       "       0.94230769, 0.94117647, 0.94      , 0.93877551, 0.9375    ,\n",
       "       0.93617021, 0.93478261, 0.93333333, 0.93181818, 0.93023256,\n",
       "       0.92857143, 0.92682927, 0.95      , 0.94871795, 0.94736842,\n",
       "       0.94594595, 0.94444444, 0.94285714, 0.94117647, 0.93939394,\n",
       "       0.9375    , 0.93548387, 0.93333333, 0.93103448, 0.92857143,\n",
       "       0.92592593, 0.92307692, 0.92      , 0.91666667, 0.91304348,\n",
       "       0.90909091, 0.95238095, 0.95      , 0.94736842, 0.94444444,\n",
       "       0.94117647, 0.9375    , 0.93333333, 0.92857143, 0.92307692,\n",
       "       0.91666667, 0.90909091, 0.9       , 0.88888889, 1.        ,\n",
       "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "18fcd8e4-91f7-4322-9f0b-f348d0ee9be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d156720d-98f1-496f-8ade-aa8dd081d868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pr_display = PrecisionRecallDisplay(precision=precision, recall=recall).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ce6b148-0332-46cb-9a1d-0b52ba514066",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptname=name+'_attff_'+str(neg_sub_index)\n",
    "torch.save(model, ptname+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5d2d1237-5882-4346-bc2c-f5dfae06eebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1819321029847347"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.83/0.84/0.836"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c2c0fc59-dee2-4a56-a946-35737b998d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9689178998963144"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9689178998963144"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
